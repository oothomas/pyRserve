import pyRserve
import pandas as pd
import numpy as np
import Support.gpa_lib as gpa_lib


conn = pyRserve.connect()
conn.r.ls()

#we are reading off the results from disk for simplicity. 
#In actual code, this will be copied from GPA module of SlicerMorph

import pandas as pd
mydata = pd.read_csv("/Users/oshanethomas/Documents/SlicerMorphData/Output/2025-04-04_10_37_00/OutputData.csv")

# some manipulation to split the centroid size and Procrustes coordinates, and sample names etc.
# these need to be replaced by PANDA frames generated by SlicerMorph in the module.

coords= mydata.copy()
coords.drop(coords.columns[0:3],axis=1,inplace=True)
conn.r.coords=coords.to_numpy()

size=mydata.centroid.to_numpy()
conn.r.size=size

conn.eval('require(geomorph)')

#arrayspecs is a geomorph until to convert 2D matrix to a 3D array that it expects
#no.LMs is hardcoded to 51 for this example
#in reality will come from GPA module.
#k is always 3. We donot work with 2D data.

conn.eval('arr=arrayspecs(coords,p=41,k=3)')

#only variable in this linear model is size against shape (i.e., LM coordinates)
#in reality these will be provided by the user inside the GPA module
#things such as Sex, Genotype, locomotion, ecology etc

conn.voidEval('gdf=geomorph.data.frame(Size=size,Coords=arr)')

#here is the linear model 
#in the actual GPA module, this will be a user input based on the covariates they created
#size is always an option. It is derived from LM coordinates. 
conn.voidEval('mod=as.formula(Coords~Size)')

#other example models
# conn.voidEval('mod=as.formula(Coords~Size*Sex+Genotype))

#that in R returns a two matrix, first row is the intercept, and the second is the coefs of size
#each subsequent variable in the formula will be other rows.
conn.voidEval('outlm=procD.lm(mod, data=gdf)')
model=conn.eval('outlm')
#conn.eval('remove(list=ls())')
#conn.shutdown()
#to shutdown Rserve. Otherwise it will stay open and contain all variable from the current session).


# --- Extract the regression coefficients from the R model ---
# modelCoeffs is an AttrArray of shape (2, 123) with row 0 = intercept, row 1 = size slope
modelCoeffs = model[2]
intercept_row = modelCoeffs[0]  # shape (123,)
slope_row     = modelCoeffs[1]  # shape (123,)

print("modelCoeffs.shape", modelCoeffs.shape)
print("intercept_row.shape", intercept_row.shape)
print("slope_row.shape", slope_row.shape)

# --- Connect to the GPA module ---
gpaWidget = slicer.modules.gpa.widgetRepresentation().self()
lmData = gpaWidget.LM

print("Before adding slope:")
print("  pcNumber:", gpaWidget.pcNumber)
print("  lmData.vec:", lmData.vec.shape)
print("  lmData.val:", lmData.val.shape)

# --- Verify number of landmarks (p) ---
p = lmData.lm.shape[0]
print("GPA says #landmarks p =", p, "; slope_row =", slope_row.shape)

# --- Reshape the slope row into (p, 3) and then flatten ---
# Use a high multiplier to exaggerate the effect; adjust the value if needed.
size_slope_flat = slope_row.reshape(3 * p, order='C').copy()
size_slope_flat *= 1000  # Increase multiplier

# --- Append the new PC vector ---
lmData.vec = np.column_stack((lmData.vec, size_slope_flat))
dummy_eigenvalue = np.median(lmData.val)
lmData.val = np.append(lmData.val, dummy_eigenvalue)

print("After adding slope:")
print("  lmData.vec:", lmData.vec.shape)
print("  lmData.val:", lmData.val.shape)

# --- Sync pcNumber and update the GPA widget ---
gpaWidget.pcNumber = lmData.vec.shape[1]

lmData.sortedEig = gpa_lib.pairEig(lmData.val, lmData.vec)
gpaWidget.updateList()
print("All done. New PC has been added.")

# --- Debug: print the norm of the new PC vector vs PC1 ---
newPC = lmData.vec[:, -1]
pc1 = lmData.vec[:, 0]
print("Norm of new PC (size slope):", np.linalg.norm(newPC))
print("Norm of PC1:", np.linalg.norm(pc1))
